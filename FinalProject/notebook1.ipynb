{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project - The best place for a beer shop\n",
    "### Applied Data Science Capstone by IBM/Coursera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Introduction](#introduction)\n",
    "* [Data](#data)\n",
    "* [Methodology](#methodology)\n",
    "* [Analysis](#analysis)\n",
    "* [Results and Discussion](#results)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last weekend I met my old friend from Moscow (capital of Russian Federation). That evening was amazing we haven’t met for three years. We talked some hours about our jobs, personal file and ideas about our future plans. Eventually he told me that he wants to start his own business. His choose is some strange for me because his is an engineer and wants to open a **beer shop**. \n",
    "\n",
    "I decided to help him by using data science power.  \n",
    "\n",
    "The city has a lot of districts. These are so different to start his own business. I try to find the best location for the new shop in accordance with my customer requirements and characteristics of urban areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data <a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to all the requirements. I collected a lot of data. The data is separated by categories\n",
    " - Data is represented on the official web sites and well formated.\n",
    " - Data from open sources (like Wikipedia)\n",
    " - GEO Data (retrieved by some web services)  \n",
    " \n",
    "Some data is not complited and has to be corrected.  \n",
    "Folowing by all the data we will try to extract payload information and aggregate it to Pandas DataFrames.  \n",
    "\n",
    "Most of our data will be collected by Yandex web service (the best service in the observed city). Also we collected data from Foursquare database.  \n",
    "\n",
    "At the end of this section we collect all the data in one big DataFrame. It'll be suitable to explore the city clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import io\n",
    "import os\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse Wiki page and extract Moscow districts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My IP was banned by Wiki because i've done too many queries so i saved this page to 'data' folder and parced it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_districts_file = './data/wiki/districts.html'\n",
    "with open(wiki_districts_file,'r', encoding='utf8') as f:\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = soup.findAll('table')\n",
    "table = None\n",
    "for t in tables:\n",
    "    th_list = set(th.text.rstrip().upper() for th in t.findAll('th'))\n",
    "    if len(th_list & {'ФЛАГ', 'ГЕРБ'}) == 2:\n",
    "        table = t\n",
    "        break;\n",
    "if table is None:\n",
    "    raise RuntimeError(\"Can not obtain table!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_districts = pd.read_html(str(table))[0]\n",
    "df_districts.drop(df_districts.columns[[0,1,2,3,6,8,9,10]], axis=1, inplace=True)\n",
    "df_districts.columns = ['DistictName', 'Borough', 'ResTotalCount']\n",
    "df_districts['ResTotalCount'] = df_districts['ResTotalCount'].str.replace('↗', '', regex=True). \\\n",
    "    str.replace('\\xa0', '', regex=True).astype(int)\n",
    "df_districts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Districts GEO points (russian map service Yandex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load API keys from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../key.json', 'r') as f:\n",
    "        cl = json.load(f)\n",
    "y_api_1 = cl['y_api_1']\n",
    "y_api_key = cl['y_api_key']\n",
    "CLIENT_ID = cl['CLIENT_ID'] \n",
    "CLIENT_SECRET =  cl['CLIENT_SECRET']  \n",
    "VERSION = '20180605' # Foursquare API version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if file already exists we don't use webservice again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/json_geo_district.json'\n",
    "if not os.path.exists(file_name):\n",
    "    print('collection data....')\n",
    "    coords = []\n",
    "    for d_name in df_districts.iterrows():\n",
    "        name = d_name[1].DistictName\n",
    "        bor = d_name[1].Borough\n",
    "        tcount = d_name[1].ResTotalCount\n",
    "        s = 'Москва,' + d_name[1].DistictName + ' район'\n",
    "        resp = requests.get('https://geocode-maps.yandex.ru/1.x/?apikey='+y_api_key+'&format=json&geocode=' + s)\n",
    "        resp.encoding = 'utf-8'\n",
    "        jpayload = json.loads(resp.text)\n",
    "        coords.append({name:{'data':jpayload,'borough':bor, 'ResTotalCount': tcount}})\n",
    "    with io.open(file_name, 'w', encoding='utf8') as json_file:\n",
    "        json.dump(coords, json_file, ensure_ascii=False)\n",
    "else:\n",
    "    print('file exists')\n",
    "    with io.open(file_name, 'r', encoding='utf8') as json_file:\n",
    "        coords = json.loads(json_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get coordinates of all districts centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_coords = []\n",
    "for item in coords:\n",
    "    for key,val in item.items():\n",
    "        #print(key)\n",
    "        cor = val['data']['response']['GeoObjectCollection']['featureMember'][0]['GeoObject']['Point']['pos'].split(' ')\n",
    "        bor = val['borough']\n",
    "        rc = val['ResTotalCount']\n",
    "        #print(cor)\n",
    "        district_coords.append([key, rc, bor, cor[1], cor[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_districts_coords = pd.DataFrame(district_coords)\n",
    "df_districts_coords.columns = ['DistrictName', 'ResTotalCount', 'Borough', 'lat', 'lng']\n",
    "df_districts_coords['lat'] = df_districts_coords['lat'].astype(float)\n",
    "df_districts_coords['lng'] = df_districts_coords['lng'].astype(float)\n",
    "df_districts_coords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Moscow district's centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_lat = 55.755814\n",
    "msk_lng = 37.617635\n",
    "map_msk = folium.Map(location=[msk_lat, msk_lng], zoom_start=9)\n",
    "\n",
    "for lat, lng, borough in zip(df_districts_coords['lat'],df_districts_coords['lng'], df_districts_coords['DistrictName']):\n",
    "    label = '{}'.format(borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    #print([lat, lng])\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_msk)  \n",
    "map_msk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to out dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_msk.save(\"out/moscow_map_districts.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and clear real estate price table (by square meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estate_price_df = pd.read_csv('data/RealEstatePrice.csv')\n",
    "estate_price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estate_price_df = pd.read_csv('data/RealEstatePrice.csv')\n",
    "estate_price_df = pd.DataFrame(list(estate_price_df[estate_price_df.columns[0]].str.split(';')))\n",
    "estate_price_df.columns = ['Place', 'Amount']\n",
    "estate_price_df['Amount'] = estate_price_df[estate_price_df.columns[1]].str.replace(' руб/м', '', regex=True). \\\n",
    "    str.replace('?', '', regex=True).str.replace(' ', '', regex=True)\n",
    "estate_price_df['Amount'] = estate_price_df['Amount'].astype(float)\n",
    "estate_price_df = estate_price_df.set_index('Place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estate_price_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get real estate price (by square meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_estate_price_df = pd.read_csv('data/AvgBoroughPrice.csv')\n",
    "avg_estate_price_df.columns = ['Borough', 'avgPrice']\n",
    "avg_estate_price_df = avg_estate_price_df.set_index('Borough')\n",
    "avg_estate_price_df.plot.bar(y='avgPrice', figsize=(5, 5))\n",
    "plt.savefig('out/real_estate_price.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get average rent price by borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rent_price = pd.read_csv('data/avgRentPrice.csv')\n",
    "avg_rent_price.columns = ['Borough','avgPrice']\n",
    "avg_rent_price = avg_rent_price.set_index('Borough')\n",
    "avg_rent_price.plot.bar(y='avgPrice', figsize=(5, 5))\n",
    "plt.savefig('out/average_rent_price_by_borough.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average monthly  income was collected my company (according to official Federal State of statistics).  \n",
    "It has so difficult calculation (including statictic by regestered model of cars, russian job service SUPERJOB etc.). In this section is displayed only result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_income = pd.read_csv('data/avgIncome.csv')\n",
    "avg_income.columns = ['Borough', 'income']\n",
    "avg_income = avg_income.set_index('Borough')\n",
    "avg_income.plot.bar(y='income', figsize=(5, 5))\n",
    "plt.savefig('out/mounthly_income.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get nearby places  by Foursquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500, LIMIT = 100):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "        jdata = requests.get(url).json()\n",
    "        try:\n",
    "            results = jdata[\"response\"]['groups'][0]['items']\n",
    "        except:\n",
    "            continue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if file already exists read from local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/foursquare_data.json'\n",
    "one = df_districts_coords\n",
    "radius = 500 \n",
    "LIMIT = 100\n",
    "if not os.path.exists(file_name):\n",
    "    print('collection data....')\n",
    "    res = getNearbyVenues(one['DistrictName'], one['lat'],one['lng'], radius = radius, LIMIT = LIMIT)\n",
    "    res.to_json(file_name)\n",
    "else:\n",
    "    print('file exists')\n",
    "    with io.open(file_name, 'r', encoding='utf8') as json_file:\n",
    "        res = pd.DataFrame(json.loads(json_file.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.columns = ['DistrictName', 'lan', 'lng', 'PlaceName', 'lan1', 'lng1', 'PlaceType']\n",
    "foursquare_df = res[['DistrictName', 'lan', 'lng', 'PlaceName', 'PlaceType']]\n",
    "foursquare_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the nearest beer shops (by Yandex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if file already exists read it from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data/json_geo_venues.json'\n",
    "if not os.path.exists(file_name):\n",
    "    print('collection data....')\n",
    "    coords = []\n",
    "    for d_name in df_districts_coords.iterrows():\n",
    "        name = d_name[1].DistrictName\n",
    "        lat = d_name[1].lat\n",
    "        lng = d_name[1].lng\n",
    "        tcount = d_name[1].ResTotalCount\n",
    "        url = 'https://search-maps.yandex.ru/v1/?text=Магазин%20пива&ll={},{}&lang=ru_RU&spn=0.03,0.03&apikey={}'.format(\n",
    "            lng,\n",
    "            lat,\n",
    "            y_api_1\n",
    "            )\n",
    "        resp = requests.get(url)\n",
    "        resp.encoding = 'utf-8'\n",
    "        jpayload = json.loads(resp.text)\n",
    "        coords.append({name:{'data':jpayload}})\n",
    "    with io.open(file_name, 'w', encoding='utf8') as json_file:\n",
    "        json.dump(coords, json_file, ensure_ascii=False)\n",
    "else:\n",
    "    print('file exists')\n",
    "    with io.open(file_name, 'r', encoding='utf8') as json_file:\n",
    "        coords = json.loads(json_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get beer shops by places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_shops = []\n",
    "for item in coords:\n",
    "    for key,val in item.items():\n",
    "        for shop in val['data']['features']:\n",
    "            shop_name = shop['properties']['name']\n",
    "            beer_shops.append([key, shop_name])\n",
    "beer_shops_df  = pd.DataFrame(beer_shops)\n",
    "beer_shops_df.columns = ['DistrictName', 'BeerShop']\n",
    "beer_shops_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get total places (exclude beer shops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foursquare_no_shops_df = foursquare_df[~foursquare_df['PlaceName'].isin(beer_shops_df['BeerShop'])]\n",
    "total_amus_places_df = foursquare_no_shops_df.groupby(['DistrictName']).count().reset_index()\n",
    "total_amus_places_df = total_amus_places_df[['DistrictName', 'lan']]\n",
    "total_amus_places_df.columns = ['DistrictName', 'TotoalAmusPlaces']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get total trademarks by places (customer decided to choose only these trademarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trademarks_df = pd.read_csv('data/Franchises.csv', delimiter =';')\n",
    "beer_already_shops_df = beer_shops_df[beer_shops_df['BeerShop'].isin(trademarks_df['RussianName'])].reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get districts where trademarks is already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_already_shops_df['already'] =  pd.DataFrame(np.ones(beer_already_shops_df.shape[0]).astype(int))\n",
    "beer_already_shops_df = beer_already_shops_df[['DistrictName', 'already']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set NEW Feature (count of beer shops / max beer shop per district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_shops_by_district_df = beer_shops_df.groupby('DistrictName').count().reset_index()\n",
    "beer_shops_by_district_df.columns = ['DistrictName', 'TotalFillness']\n",
    "beer_shops_by_district_df['TotalFillness'] = beer_shops_by_district_df['TotalFillness'] / \\\n",
    "    beer_shops_by_district_df['TotalFillness'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all the data in one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estate_price_df = estate_price_df.reset_index()\n",
    "estate_price_df.columns = ['DistrictName', 'avgPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_df = pd.merge(df_districts_coords, beer_shops_by_district_df, on='DistrictName',  how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark if already is the same beer shop in district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_df = pd.merge(final_data_df, beer_already_shops_df, on='DistrictName', how='left')\n",
    "final_data_df.fillna(0, inplace=True)\n",
    "final_data_df['already'] = final_data_df['already'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some districts does not has price value so we replace it by average value from avg_estate_price_df dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(final_data_df, avg_estate_price_df, on='Borough', how='left')\n",
    "df = pd.merge(df, estate_price_df, on=['DistrictName'], how='left')\n",
    "df['avgPrice'] = df['avgPrice_y'].where(df['avgPrice_y'].notna(),df['avgPrice_x'])\n",
    "final_data_df = df[['DistrictName','ResTotalCount','Borough','lat','lng','TotalFillness','already','avgPrice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add rent price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_df = pd.merge(final_data_df, avg_rent_price, on='Borough', how='left', suffixes = ('', '_rent'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add average income by district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data_df = pd.merge(final_data_df, avg_income, on='Borough', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add total count of interesting places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_df = pd.merge(final_data_df, total_amus_places_df, on='DistrictName', how='left')\n",
    "final_data_df['TotoalAmusPlaces'].fillna((final_data_df['TotoalAmusPlaces'].mean()), inplace=True)\n",
    "final_data_df['TotoalAmusPlaces'] = final_data_df['TotoalAmusPlaces'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology <a name=\"methodology\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we already have corrected and cleared data.  \n",
    "We have\n",
    "- Total count of residents in district\n",
    "- \"Total fillness\" - how many beer shops in district\n",
    "- 1/0 if district has the same type of beer shop as customer selected\n",
    "- Average real estate price (by square meter)\n",
    "- Average rent price\n",
    "- Avarage residents monthly income \n",
    "- Total count of interesting places in district  \n",
    "\n",
    "By this information we can separate the districts by special groups.   \n",
    "We will use **K-means algorithm**. It's suitable for this task. After splitting our districts by groups we'll explore them. This exploration will help us to detect economic situation in each district. By ssummary analysis we'll make decision what the best district is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect clusters of districts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select nessesary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = final_data_df[['ResTotalCount', 'TotalFillness', 'already', 'avgPrice', \\\n",
    "    'avgPrice_rent', 'income', 'TotoalAmusPlaces']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of clusters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kclusters = 5\n",
    "# run k-means algorithm\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(data_df)\n",
    "klabels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply clusters to the whole DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_df['cluster'] = klabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot cluster map and customer's house place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_lat = 55.755814\n",
    "msk_lng = 37.617635\n",
    "map_clusters = folium.Map(location=[msk_lat, msk_lng], zoom_start=9)\n",
    "\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(final_data_df['lat'], final_data_df['lng'], final_data_df['DistrictName'], \\\n",
    "                                  final_data_df['cluster'].astype(int)):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "\n",
    "# custormer house point\n",
    "cust_lat = 55.664843\n",
    "cust_lng = 37.766175     \n",
    "folium.Marker(\n",
    "    [cust_lat, cust_lng],\n",
    "    popup='Customer House',\n",
    "    icon=folium.Icon(color='green', icon='info-sign')\n",
    ").add_to(map_clusters)\n",
    "\n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save map to out directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_clusters.save(\"out/moscow_map_clusters.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis <a name=\"analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster N0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_df[final_data_df['cluster']==0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cluster has middle range income, middle range rent price and the same shops are almost absent. \"Already\" mean (0.06) (total ratio of selected trademarks) is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data_df[final_data_df['cluster']==1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cluster represents extremely rich people. Rent price is too high and this cluster has a lot of bars/restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster N2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_df[final_data_df['cluster']==2].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cluster has lower income and higher rent price then cluster №0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster N3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_df[final_data_df['cluster']==3].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cluster has the lowest rent price and income. There are not the selected trademarks in this cluster. There are not too many bars/restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster N4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_df[final_data_df['cluster']==4].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cluster has approximately the same income as cluster №0 but rent price is higher. \"TotalFillness\" parameter is too high (amount of bars/pub etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion<a name=\"results\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method split Moscow by clusters. Total number of clusters was chosen experimentally. **The best value is five**. Each cluster represents only one segment of the city districts groped by several parameters. The Analysis gets us some decisions. \n",
    "\n",
    "- **Cluster №0 has medium parameters (income, rent price, total count of beer bars/shops etc.)**  \n",
    "This cluster is the most suitable for opening small business. \n",
    "\n",
    "- **Cluster №1 has high parameters.**  \n",
    "This cluster is not good for small busines. Rich people don't go to shops. They order goods on the internet or some services intended for the rich.  \n",
    "\n",
    "- **Cluster №2 is good for opening small business but it has worse parameters then cluster №0. So we don't consider it.** \n",
    "\n",
    "- **Cluster №3 represents the poorest people of the city**.  \n",
    "This part of residents doesn't like craft beer. They drink beer in tin cans only. So we drop this cluster too.\n",
    "\n",
    "- **Cluster №4 is the same as Cluster №0 but rent price is higher**.  \n",
    "This cluster is good for small business too but there is high competition in it.\n",
    "\n",
    "So we have two clusters (0,4) for opening a small beer shop. One of the customer's requirements is \"Closer to my home\". This distances may be calculated by Yandex of Google services, but these services are not free now. Indeed we shouldn't use these services.   \n",
    "\n",
    "By skimming the clustered map, we can see that the customer's house is in cluster №0, so **the best choice is cluster N0**.\n",
    "\n",
    "So the best districts (in Russian):  \n",
    "- Южнопортовый \n",
    "- Нижегородский \n",
    "- Рязанский \n",
    "- Текстильщики \n",
    "- Печатники \n",
    "- Кузьминки \n",
    "- Люблино \n",
    "- Марьино \n",
    "- Выхино-Жулебино \n",
    "- Капотня \n",
    "- Некрасовка \n",
    "- Лефортово "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The customer wants to consider **only these franchises**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trademarks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's really right. All these trademarks have been operating in Moscow for many years.  \n",
    "- Pivoteka 465, Piv&ko are toщ expensive. So the customer needs to take a bank loan.\n",
    "- Kalinkino, Pinta and BeerMag have approximately the same parameters(payback Period, monthly profit etc.).  \n",
    "\n",
    "So **Kalinkino, Pinta and BeerMag are the most appropriate franchises**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion<a name=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this project is to help my customer (my old friend from Moscow) to make a right choice. By collecting a lot of statistics data we separated the city by several segments (using K-means algorithm). We found out that some districts are not good for opening his own small business.  \n",
    "\n",
    "In accordance with the requirements of the customer, we've chosen the suitable area of the city.  **This area is the same as the customer's home locates. So we shouldn't explore city traffic jams.**  \n",
    "\n",
    "Of the franchises chosen by the customer, we selected the most suitable. These three franchises **do not require a bank loan** to open a small shop.  \n",
    "\n",
    "The final decision of optimal business strategy will be completed by the customer only. But now the customer has useful information to make a right choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
